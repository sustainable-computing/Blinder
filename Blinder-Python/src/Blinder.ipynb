{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1d2ed-0d1e-46f4-9b38-29c53f8d2099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "#!/home/xyang18/miniconda3/envs/pytorch/bin/ python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import *\n",
    "from update import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from dataset_loader import *\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.verbose = 1\n",
    "        self.gpu_id = 3\n",
    "        self.seed = 30 # random seed\n",
    "        self.z_dim = 25 # size of latent representation\n",
    "        self.frac = 0.4 # fraction of users selected in the training per epoch\n",
    "        self.epochs = 20 # number of training epoches\n",
    "        self.inner_update_step = 1  # task-level inner update steps\n",
    "        self.aux_ep = 5  # training steps of the discriminator\n",
    "        self.TRAIN_MODEL = True\n",
    "        self.k_spt = 16 # size of the support set\n",
    "        self.k_qry = 48 # size of the query set\n",
    "        self.k_finetune = 16 # samples used for finetuning\n",
    "        self.batch_size = 256 # batchsize for test only\n",
    "        self.lr = 1e-3 # learning rate\n",
    "        self.maml_lr = 1e-4 # meta learning rate\n",
    "        self.alpha = 0.2 # hyper parameter for auxloss\n",
    "        self.finetune_step = 10\n",
    "        self.train_sampler = 'smote' # 'none' no sampler used in training set; 'smote': smote sampler\n",
    "        self.dataset = 'mobi' # dataset, 'mobi' for MobiAct; 'motion' for MotionSense\n",
    "        self.anonymize = 'random' # 'determ': deterministic anonymization; 'random': stochastic anonymization\n",
    "        self.num_users = 36 # total number of users in the dataset\n",
    "        self.num_public_attr = 4 # total number of public attributes\n",
    "        self.num_private_attr = 2  # total number of private attributes\n",
    "        self.private = 'gender' # 'weight', 'gender'\n",
    "        self.smote_num = 4000\n",
    "args = Args()\n",
    "\n",
    "\n",
    "# args = args_parser()\n",
    "\n",
    "\n",
    "if args.dataset=='mobi':\n",
    "    args.sample_size=768\n",
    "    args.num_users = 36\n",
    "    args.num_public_attr=4\n",
    "    args.smote_num = 4000\n",
    "elif args.dataset=='motion':\n",
    "    args.sample_size=256\n",
    "    args.num_users = 24\n",
    "    args.num_public_attr=4\n",
    "    args.smote_num = 600\n",
    "    \n",
    "if args.private == 'weight':\n",
    "    args.num_private_attr = 3\n",
    "elif args.private == 'gender':\n",
    "    args.num_private_attr = 2\n",
    "        \n",
    "\n",
    "activities = np.arange(args.num_public_attr).astype(int)\n",
    "\n",
    "comment = ''\n",
    "model_folder = '../models/Blinder_' + str(args.num_users) + '_' + args.dataset + '_' + args.private + '_ep' + str(args.epochs) + '_localep' + str(\n",
    "    args.inner_update_step) +'_spt' + str(args.k_spt) + '_qry' + str(args.k_qry) + '_seed' + str(args.seed) + '_trainsamp_' + args.train_sampler + comment + '/'\n",
    "\n",
    "# print(model_folder)\n",
    "\n",
    "# Create folder to save models\n",
    "try:\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.mkdir(model_folder)\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "\n",
    "# Save a copy of all the arguments\n",
    "save_exp_details(args, model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cc3ed-2a8a-4c13-b709-59151bad3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = os.path.abspath('..')\n",
    "# logger = SummaryWriter('../logs')\n",
    "\n",
    "# torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "if args.gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c13912-f657-4bcb-aabd-0aa4c2dfa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to dump output to txt file\n",
    "# sys.stdout = open(model_folder+'output.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb47df7-397d-4402-a339-6d75c9333ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if args.dataset=='mobi':\n",
    "    x_train, x_test, activity_train_label, activity_test_label, gender_train_label, gender_test_label, weight_train_label, weight_test_label, user_groups, user_groups_test, id_train, id_test = load_mobiact(args)\n",
    "elif args.dataset=='motion':\n",
    "    x_train, x_test, activity_train_label, activity_test_label, gender_train_label, gender_test_label, user_groups, user_groups_test, id_train, id_test = load_motionsense()\n",
    "\n",
    "if args.private=='gender':\n",
    "    private_train_label = gender_train_label\n",
    "    private_test_label = gender_test_label\n",
    "elif args.private == 'weight':\n",
    "    private_train_label = weight_train_label\n",
    "    private_test_label = weight_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974472ee-4e1f-46fe-b49a-4b6ed8768a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for every client, balance public attribtues using SMOTE\n",
    "def get_train_loaders(args, x_train, private_train_label, public_train_label):\n",
    "    user_train_loaders = {}\n",
    "    if args.dataset=='mobi':\n",
    "        x_train = np.reshape(x_train, [x_train.shape[0], args.sample_size])\n",
    "\n",
    "    for user_id in range(args.num_users):\n",
    "        # generate weights for samples        \n",
    "        if args.train_sampler == 'smote':\n",
    "            user_filter = [True if x in user_groups[user_id] else False for x in id_train]\n",
    "            raw_user_tensor_x = x_train[user_filter]  # transform to torch tensor\n",
    "            raw_user_tensor_y = private_train_label[user_filter]  # onehot\n",
    "            user_act_onehot = public_train_label[user_filter]\n",
    "            user_act = np.argmax(user_act_onehot, axis=1)\n",
    "            raw_act_counter=Counter(user_act)\n",
    "            print('User', user_id, ': Original dataset %s' % raw_act_counter)\n",
    "            smote_strategy = {}\n",
    "            for i in range(args.num_public_attr):\n",
    "                smote_strategy[i] = max(args.smote_num, raw_act_counter[i])\n",
    "            sm = SMOTE(sampling_strategy=smote_strategy, k_neighbors=5)\n",
    "            X_res, y_res = sm.fit_resample(raw_user_tensor_x, user_act)\n",
    "            down_strategy = {}\n",
    "            for i in range(args.num_public_attr):\n",
    "                down_strategy[i] = args.smote_num\n",
    "            rus = RandomUnderSampler(random_state=args.seed, sampling_strategy=down_strategy)\n",
    "            X_res, y_res = rus.fit_resample(X_res, y_res)\n",
    "            print('User', user_id, ': Resampled dataset %s' % Counter(y_res))\n",
    "            user_tensor_x = torch.as_tensor(X_res.astype('float32'))\n",
    "            y_res = to_categorical(y_res, num_classes=args.num_public_attr)\n",
    "            user_tensor_act = torch.as_tensor(y_res.astype('float32'))\n",
    "            user_gen = np.argmax(raw_user_tensor_y[0]) # user gender, digit, not one-hot\n",
    "            new_gens = np.ones(len(X_res)) * user_gen # fill new gender array with user's gender\n",
    "            user_tensor_y = torch.from_numpy(to_categorical(new_gens, num_classes=args.num_private_attr).astype('float32'))\n",
    "            user_dataset = TensorDataset(user_tensor_x, user_tensor_y, user_tensor_act)\n",
    "            user_train_loader = list(torch.utils.data.DataLoader(user_dataset, batch_size=args.k_spt + args.k_qry, shuffle=True, pin_memory=True))               \n",
    "        elif args.train_sampler == 'none':\n",
    "            user_filter = [True if x in user_groups[user_id] else False for x in id_train]\n",
    "            user_tensor_x = torch.from_numpy(x_train[user_filter].astype('float32'))  # transform to torch tensor\n",
    "            user_tensor_y = torch.from_numpy(private_train_label[user_filter].astype('float32'))  # onehot\n",
    "            user_tensor_act = torch.from_numpy(public_train_label[user_filter].astype('float32'))\n",
    "            user_dataset = TensorDataset(user_tensor_x, user_tensor_y, user_tensor_act)\n",
    "            user_train_loader = list(torch.utils.data.DataLoader(user_dataset, batch_size=args.k_spt + args.k_qry, shuffle=True, pin_memory=True))\n",
    "        user_train_loaders[user_id] = user_train_loader\n",
    "    return user_train_loaders\n",
    "\n",
    "if args.TRAIN_MODEL:\n",
    "    user_train_loaders = get_train_loaders(args, x_train, private_train_label, activity_train_label)\n",
    "    dataset_generators = {}\n",
    "    for uid in range(args.num_users):\n",
    "        dataset_generators[uid] = iter(user_train_loaders[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d015330-7cc3-41e7-bc20-beaf24719ae1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if args.TRAIN_MODEL:\n",
    "    train_loss, train_aux_loss, train_accuracy = [], [], []\n",
    "    \n",
    "    global_encoder = Encoder(args.z_dim, args.sample_size)\n",
    "    global_decoder = Decoder(args.z_dim, args.num_private_attr, args.num_public_attr, args.sample_size)\n",
    "    global_aux = AUX(args.z_dim, numLabels=args.num_private_attr)\n",
    "\n",
    "    global_encoder.to(device)\n",
    "    global_decoder.to(device)\n",
    "    global_aux.to(device)\n",
    "\n",
    "    global_encoder.train()\n",
    "    global_decoder.train()\n",
    "    global_aux.train()\n",
    "\n",
    "    optimizer_encoder = torch.optim.Adam(global_encoder.parameters(), lr=args.lr)\n",
    "    optimizer_decoder = torch.optim.Adam(global_decoder.parameters(), lr=args.lr)\n",
    "    optimizer_aux = torch.optim.Adam(global_aux.parameters(), lr=args.lr)\n",
    "    \n",
    "    print(\"########################################################\")\n",
    "\n",
    "    # get smallest number of local batches, should be the same if data is rebalanced\n",
    "    min_dataset_batch = sys.maxsize\n",
    "    for i in range(args.num_users):\n",
    "        min_dataset_batch = min(min_dataset_batch, len(user_train_loaders[i]))\n",
    "    print('Min Dataset batch:', min_dataset_batch)\n",
    "    \n",
    "    # number of selected users\n",
    "    m = max(int(args.frac * args.num_users), 1)\n",
    "        \n",
    "    for epoch in tqdm(range(args.epochs)):\n",
    "        print(f'\\n | Global Training Round : {epoch + 1} |')\n",
    "\n",
    "        # randomly select m users from total users\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "        print(\"Participating Users:\", idxs_users)\n",
    "        \n",
    "        for comm_round in range(min_dataset_batch):\n",
    "            sum_qry_loss = 0\n",
    "            sum_qry_aux_loss = 0\n",
    "            sum_qry_recon_loss = 0\n",
    "            sum_qry_kld_loss = 0\n",
    "            \n",
    "            local_encoder_grads = []\n",
    "            local_decoder_grads = []\n",
    "            local_aux_grads = []\n",
    "\n",
    "            # local training steps:\n",
    "            for idx in idxs_users:\n",
    "                try:\n",
    "                    train_x, train_y, train_act = next(dataset_generators[idx])\n",
    "                except StopIteration:\n",
    "                    # restart the generator if the previous generator is exhausted.\n",
    "                    dataset_generators[idx] = iter(user_train_loaders[idx])\n",
    "                    train_x, train_y, train_act = next(dataset_generators[idx])\n",
    "                \n",
    "                train_act = train_act.type(torch.LongTensor)\n",
    "\n",
    "                local_model = Client(args=args, device=device)\n",
    "                encoder_grads, decoder_grads, aux_grads, qry_loss, qry_recons_loss, qry_kld_loss, qry_auxLoss = local_model.update(\n",
    "                    data_train_x=train_x, data_train_y=train_y, data_train_act=train_act,\n",
    "                    encoder_model=copy.deepcopy(global_encoder),\n",
    "                    decoder_model=copy.deepcopy(global_decoder),\n",
    "                    aux_model=copy.deepcopy(global_aux))\n",
    "\n",
    "                local_encoder_grads.append(copy.deepcopy(encoder_grads))\n",
    "                local_decoder_grads.append(copy.deepcopy(decoder_grads))\n",
    "                local_aux_grads.append(copy.deepcopy(aux_grads))\n",
    "\n",
    "                sum_qry_loss += qry_loss\n",
    "                sum_qry_recon_loss += qry_recons_loss\n",
    "                sum_qry_kld_loss += qry_kld_loss\n",
    "                sum_qry_aux_loss += qry_auxLoss\n",
    "\n",
    "            avg_qry_loss = sum_qry_loss/m\n",
    "            avg_qry_recon_loss = sum_qry_recon_loss/m\n",
    "            avg_qry_kld_loss = sum_qry_kld_loss/m\n",
    "            avg_qry_aux_loss = sum_qry_aux_loss/m\n",
    "\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "            optimizer_aux.zero_grad()\n",
    "\n",
    "            # Average local gradients\n",
    "            avg_encoder_grads = average_gradients(local_encoder_grads)\n",
    "            avg_decoder_grads = average_gradients(local_decoder_grads)\n",
    "            avg_aux_grads = average_gradients(local_aux_grads)\n",
    "            \n",
    "            # Update global models\n",
    "            global_encoder = update_global_grads(global_encoder, avg_encoder_grads)\n",
    "            global_decoder = update_global_grads(global_decoder, avg_decoder_grads)\n",
    "            global_aux = update_global_grads(global_aux, avg_aux_grads)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "            optimizer_aux.step()\n",
    "\n",
    "            train_loss.append(avg_qry_loss)\n",
    "            train_aux_loss.append(avg_qry_aux_loss)\n",
    "            \n",
    "            if (args.verbose and comm_round % 50 == 0):\n",
    "                print(\"Global EP %d, Local Comm Round %d: Total loss: %f, AUX loss: %f, MSE: %f, KLD loss: %f\" % \n",
    "                      (epoch+1, comm_round, avg_qry_loss, avg_qry_aux_loss, avg_qry_recon_loss, avg_qry_kld_loss))\n",
    "                \n",
    "        # Save model at the end of every epoch in case of losing progress caused by numerical instability\n",
    "        path_encoder, path_decoder, path_aux = get_paths_encoder_decoder_aux(model_folder=model_folder, z_dim=args.z_dim, model=args.model)\n",
    "        torch.save(global_encoder.state_dict(), path_encoder)\n",
    "        torch.save(global_decoder.state_dict(), path_decoder)\n",
    "        torch.save(global_aux.state_dict(), path_aux)\n",
    "\n",
    "    # Save loss plots\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    lines1, = ax1.plot(np.arange(len(train_loss)), train_loss)\n",
    "    fig1.savefig(model_folder + 'train_loss.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close(fig1)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    lines2, = ax2.plot(np.arange(len(train_aux_loss)), train_aux_loss)\n",
    "    fig2.savefig(model_folder + 'train_aux_loss.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close(fig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41acb4ed-4658-4618-ba0e-db214961bd93",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03814bd-958f-4659-99fd-8abb300c82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load desired inference model & private attribute inference model\n",
    "def load_eval_models(args):\n",
    "    path = \"../eval_models/\"\n",
    "    if args.dataset=='mobi':\n",
    "        eval_act_model = load_model(path + \"Inference models MobiAct/activity_model_DC.hdf5\")\n",
    "        if args.private=='gender':\n",
    "            eval_private_model = load_model(path + \"Inference models MobiAct/gender_model_DC.hdf5\")\n",
    "        elif args.private=='weight':\n",
    "            eval_private_model = load_model(path + \"Inference models MobiAct/weight_model_DC.hdf5\")\n",
    "    elif args.dataset=='motion':\n",
    "        eval_act_model = load_model(path + \"Inference models MotionSense/my_activity_model_mlp.hdf5\")\n",
    "        eval_private_model = load_model(path + \"Inference models MotionSense/my_gender_model_mlp.hdf5\")\n",
    "    return eval_act_model, eval_private_model\n",
    "\n",
    "eval_act_model, eval_private_model = load_eval_models(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204a7fd-2d71-491c-be5e-be3e089ec398",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset=='mobi':\n",
    "    public_txt_labels = [\"wlk\",\"std\", \"jog\", \"ups\"]\n",
    "elif args.dataset =='motion':\n",
    "    public_txt_labels = [\"dws\",\"ups\", \"wlk\", \"jog\"]\n",
    "    \n",
    "if args.private=='gender':\n",
    "    private_txt_labels = [\"m\", \"f\"]\n",
    "elif args.private=='weight':\n",
    "    private_txt_labels = [\"<=70\", \"70-90\", \">90\"]\n",
    "\n",
    "enc_model, dec_model, aux_model = get_models_encoder_decoder_aux(model_folder, args)\n",
    "enc_model, dec_model, aux_model = enc_model.to(device), dec_model.to(device), aux_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720739d6-e8cf-4e01-9c5c-d680a93333cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_act_true, Y_act_pred, Y_gen_true, Y_gen_pred = inference(args, device, enc_model, dec_model, \n",
    "                                                           eval_act_model, eval_private_model, \n",
    "                                                           x_test, activity_test_label, private_test_label, \n",
    "                                                           public_txt_labels, private_txt_labels)\n",
    "\n",
    "print(\"EVALUATION ON ALL TEST SET:\")\n",
    "print(\"Public Attribute Identification:\")\n",
    "print_accu_confmat_f1score(Y_act_true, Y_act_pred, public_txt_labels)\n",
    "print(\"Private Attribute Identification:\")\n",
    "print_accu_confmat_f1score(Y_gen_true, Y_gen_pred, private_txt_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
